---
title: MySQL面试
permalink: /manuscripts/battle-interview/mysql.html
---

# MySQL面试

## 基础架构

> 由外向里，逐步深入

- 连接层：**完成一些类似于连接处理、授权认证、及相关的安全方案**，引入了**线程池**的概念
- 服务层：完成大部分的核心服务功能， 包括查询解析、分析、优化、缓存、以及所有的内置函数，所有跨存储引擎的功能也都在这一层实现，包括触发器、存储过程、视图等
- 引擎层：**存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信**
- 存储层：将数据存储在运行于该设备的文件系统之上，并完成与存储引擎的交互

## 存储引擎

- InnoDB 【MySQL 默认的存储引擎，支持**事务、行级锁定和外键**】
- MyISAM【**不支持事务，不支持外键**】
- Memory
- NDB
- ......

> 不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能，使用不同的存储引擎，还可以获得特定的功能

**一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求**，使用合适的存储引擎，将会提高整个数据库的性能

查看存储引擎命令：

```bash
-- 查看支持的存储引擎
SHOW ENGINES

-- 查看默认存储引擎
SHOW VARIABLES LIKE 'storage_engine'

--查看具体某一个表所使用的存储引擎，这个默认存储引擎被修改了！
show create table tablename

--准确查看某个数据库中的某一表所使用的存储引擎
show table status like 'tablename'
show table status from database where name="tablename"
```

**InnoDB 是聚簇索引，MyISAM 是非聚簇索引**。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。

- MyISAM表会把自增主键的最大ID 记录到**数据文件**中，重启MySQL自增主键的最大ID也不会丢失
- InnoDB 表只是把自增主键的最大ID记录到**内存**中，所以重启数据库或对表进行OPTION操作，都会导致最大ID丢失。

## 数据类型

- 整数类型：`BIT`、`BOOL`、`TINY` `INT`、`SMALL INT`、`MEDIUM INT`、 `INT`、 `BIG INT`
- 浮点数类型：`FLOAT`、`DOUBLE`、`DECIMAL`
- 字符串类型：`CHAR`、`VARCHAR`、`TINY TEXT`、`TEXT、MEDIUM TEXT`、`LONGTEXT`、`TINY` `BLOB`、`MEDIUM BLOB`、`LONG BLOB`
- 日期类型：`Date`、`DateTime`、`TimeStamp`、`Time`、`Year`
- 其他数据类型：`BINARY`、`VARBINARY`、`ENUM`、`SET`、`Geometry`、`Point`、`MultiPoint`、`LineString`、`MultiLineString`、`Polygon`、`GeometryCollection`等

> BLOB和TEXT有什么区别？   **字符串类型是：`SET`、`BLOB`、`ENUM`、`CHAR`、`TEXT`、`VARCHAR`**

- BLOB是一个二进制对象，可以容纳可变数量的数据。有四种类型的BLOB：TINYBLOB、BLOB、MEDIUMBLO和 LONGBLOB
- TEXT是一个不区分大小写的BLOB。四种TEXT类型：TINYTEXT、TEXT、MEDIUMTEXT 和 LONGTEXT。
- BLOB 保存二进制数据，TEXT 保存字符数据。

## 索引（单独重点来）

> 索引（Index）是帮助MySQL高效获取数据的数据结构，所以说**索引的本质是：数据结构**

索引本身也很大，不可能全部存储在内存中，**一般以索引文件的形式存储在磁盘上**

优点:

- **提高数据检索效率，降低数据库IO成本**
- **降低数据排序的成本，降低CPU的消耗**

缺点:

- 索引也是一张表，保存了主键和索引字段，并指向实体表的记录，所以也需要占用内存
- 虽然索引大大提高了查询速度，同时却会降低更新表的速度，【更新表的时候需要更新索引】

## 事务

> 主要用于处理操作量大，复杂度高的数据

基本要素（ACID）:

- **A (Atomicity) 原子性**：整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样
- **C (Consistency) 一致性**：在事务开始之前和事务结束以后，数据库的**完整性约束**没有被破坏
- **I (Isolation)隔离性**：一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰【**加锁实现**】
- **D (Durability) 持久性**：在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚

**并发事务处理带来的问题**

- 更新丢失（Lost Update)： 事务A和事务B选择同一行，然后基于最初选定的值更新该行时，由于两个事务都不知道彼此的存在，就会发生丢失更新问题
- 脏读(Dirty Reads)：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据
- 不可重复读（Non-Repeatable Reads)：事务 A 多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。
- 幻读（Phantom Reads)：幻读与不可重复读类似。它发生在一个事务A读取了几行数据，接着另一个并发事务B插入了一些数据时。在随后的查询中，事务A就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为**幻读**。

**幻读和不可重复读的区别：**

- **不可重复读的重点是修改**：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改）
- **幻读的重点在于新增或者删除**：在同一事务中，同样的条件，第一次和第二次读出来的记录数不一样。（因为中间有其他事务提交了插入/删除）

**并发事务处理带来的问题的解决办法：**

- “更新丢失”通常是应该完全避免的。但防止更新丢失，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据加必要的锁来解决，因此，防止更新丢失应该是应用的责任。
- “脏读” 、 “不可重复读”和“幻读” ，其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决：
  - 一种是加锁：在读取数据前，对其加锁，阻止其他事务对数据进行修改。
  - 另一种是数据多版本并发控制（MultiVersion Concurrency Control，简称 **MVCC** 或 MCC），也称为多版本数据库：不用加任何锁， 通过一定机制生成一个数据**请求时间点**的一致性数据快照 （Snapshot)， 并用这个快照来提供一定级别 （语句级或事务级） 的一致性读取。从用户的角度来看，好象是数据库可以提供同一数据的多个版本。

## 事务隔离级别

数据库事务的隔离级别有4种，由低到高分别为

- **READ-UNCOMMITTED(读未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。
- **READ-COMMITTED(读已提交)：** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。
- **REPEATABLE-READ(可重复读)：** 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。
- **SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。

> 简单来说，Serializable可串行化会在读取的每一行数据上都加锁，所以可能导致大量的超时和锁争用问题。这种事务隔离级别效率低下，比较耗数据库性能，一般不使用。

**数据库的事务隔离越严格，并发副作用越小，但付出的代价就越大，并发性就越差，因为事务隔离实质上就是使事务在一定程度上“串行化”进行，这显然与“并发”是矛盾的**

> MySQL InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）**。我们可以通过`SELECT @@tx_isolation;`命令来查看，MySQL 8.0 该命令改为`SELECT @@transaction_isolation;`

与 SQL 标准不同的地方在于InnoDB 存储引擎在 **REPEATABLE-READ（可重读）**事务隔离级别下使用的是`Next-Key Lock` 算法，**因此可以避免幻读的产生**，这与其他数据库系统(如 SQL Server)是不同的。所以说InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）已经可以完全保证事务的隔离性要求，**即达到了 SQL标准的 SERIALIZABLE(可串行化)隔离级别，而且保留了比较好的并发性能**。

数据库使用锁是为了支持更好的并发，提供数据的完整性和一致性。InnoDB是一个支持行锁的存储引擎，锁的类型有：

- 共享锁（S）
- 排他锁（X）
- 意向共享（IS）
- 意向排他（IX）

对应行锁的三种算法：

- Record Lock：单个行记录上的锁。
- Gap Lock：间隙锁，锁定一个范围，但不包括记录本身。**GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。**
- Next-Key Lock：1+2，锁定一个范围，并且**锁定记录本身**。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。

为了提供更好的并发，InnoDB提供了**非锁定读**：不需要等待访问行上的锁释放，读取行的一个快照。**该方法是通过InnoDB的一个特性：MVCC来实现的**。

## MVCC 多版本并发控制

- **乐观（optimistic）并发控制**
- **悲观（pressimistic）并发控制**

MVCC 是行级锁的一个变种，但它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制有所不同，但大都实现了**非阻塞的读操作**，写操作也只是锁定必要的行

**MVCC 的实现是通过保存数据在某个时间点的快照来实现的**。也就是说不管需要执行多长时间，每个事物看到的数据都是一致的。

> InnoDB 的 MVCC，是通过在每行记录后面保存两个隐藏的列来实现。这两个列，一个保存了行的创建时间，一个保存行的过期时间（删除时间）。当然存储的并不是真实的时间，而是系统版本号（system version number）。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。

保存这两个额外系统版本号，使大多数操作都不用加锁。使数据操作简单，性能很好，并且也能保证只会读取到符合要求的行。不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作和一些额外的维护工作。

**MVCC 只在 COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作。**

## 事务的实现

> 事务的实现就是如何实现ACID特性

**MySQL 中支持事务的存储引擎有 InnoDB 和 NDB**

**事务的隔离性是通过锁实现，而事务的原子性、一致性和持久性则是通过事务日志实现**

- **redo log（重做日志**） 实现持久化和原子性
- **undo log（回滚日志）** 实现一致性

## MySQL日志分类

> 参考：<https://www.cnblogs.com/myseries/p/10728533.html>

- **错误日志**：记录出错信息，也记录一些警告信息或者正确的信息。
- **查询日志**：记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行。
- **慢查询日志**：设置一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中。
- **二进制日志**：记录对数据库执行更改的所有操作。
- **中继日志**：中继日志也是二进制日志，用来给slave 库恢复
- **事务日志**：重做日志redo和回滚日志undo 【redo和undo都属于处理事务的日志类型】

> 事务日志均可以视为一种恢复操作，redo_log是恢复提交事务修改的页操作，而undo_log是回滚行记录到特定版本；redo_log是物理日志，记录页的物理修改操作，而undo_log是逻辑日志

- redo 重做日志 【实现持久性和一致性】
  作用：确保事务的持久性，防止在发生故障，脏页未写入磁盘。重启数据库会进行redo log执行重做，到达事务一致性
  
- undo 回滚日志 【实现原子性】
  作用：保证数据的原子性，记录事务发生之前的数据的一个版本，用于回滚。
  innodb事务的可重复读和读取已提交 隔离级别就是通过mvcc+undo实现

- errorlog 错误日志
  作用：Mysql本身启动、停止、运行期间发生的错误信息
  
- slow query log 慢查询日志
  作用：记录执行时间过长的sql，时间阈值可以配置，只记录执行成功

- binlog 二进制日志
  作用：用于主从复制，实现主从同步
  
- relay log 中继日志
  作用：用于数据库主从同步，将主库发送来的binlog先保存在本地，然后从库进行回放
  
- general log 普通日志
  作用：记录数据库操作明细，默认关闭，开启会降低数据库性能

## MySQL锁机制

> 锁是计算机协调多个进程或线程并发访问某一资源的机制,是数据库为了保证数据的一致性，而使各种共享资源在被并发访问变得有序所设计的一种规则

### 锁的分类

**从对数据操作的类型分类**：

- **读锁**（共享锁）：针对同一份数据，多个读操作可以同时进行，不会互相影响
- **写锁**（排他锁）：当前写操作没有完成前，它会阻断其他写锁和读锁

**从对数据操作的粒度分类**：

> 为了尽可能提高数据库的并发度，每次锁定的数据范围越小越好，但需要在高并发响应和系统性能两方面进行平衡

**表级锁**：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低（MyISAM 和 MEMORY 存储引擎采用的是表级锁）；

**行级锁**：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高（InnoDB 存储引擎既支持行级锁也支持表级锁，但默认情况下是采用行级锁）；

**页面锁**：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

> 适用：从锁的角度来说，表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用
>
> 而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用

| 存储引擎 | 行锁 | 表锁 | 页锁 |
| -------- | ---- | ---- | ---- |
| MyISAM   |      | √    |      |
| BDB      |      | √    | √    |
| InnoDB   | √    | √    |      |
| Memory   |      | √    |      |

## MyISAM 表锁

MyISAM 的表锁有两种模式：

- 表共享读锁 （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；
- 表独占写锁 （Table Write Lock）：会阻塞其他用户对同一表的读和写操作；

**MyISAM 表的读操作与写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后， 只有持有锁的线程可以对表进行更新操作。 其他线程的读、 写操作都会等待，直到锁被释放为止。**

默认情况下，写锁比读锁具有更高的优先级：当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求。

## InnoDB 行锁

InnoDB 实现了以下两种类型的**行锁**：

- 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。
- 排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。

为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是**表锁**：

- 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。
- 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。

**索引失效会导致行锁变表锁**。比如 vchar 查询不写单引号的情况。

### 加锁机制

**乐观锁与悲观锁是两种并发控制的思想，可用于解决丢失更新问题**

乐观锁会“乐观地”假定大概率不会发生并发更新冲突，访问、处理数据过程中不加锁，只在更新数据时再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务。用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式

悲观锁会“悲观地”假定大概率会发生并发更新冲突，访问、处理数据前就加排他锁，在整个数据处理过程中锁定数据，事务提交或回滚后才释放锁。另外与乐观锁相对应的，**悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。**

### 锁模式(InnoDB有三种行锁的算法)

- **记录锁(Record Locks)**
- **间隙锁（Gap Locks）**
- **临键锁(Next-key Locks)**【解决幻读问题】

**记录锁(Record Locks)**： 单个行记录上的锁。对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项；

**间隙锁（Gap Locks）**： 当我们使用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙”。

InnoDB 也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。

对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。

**间隙锁基于非唯一索引，它锁定一段范围内的索引记录**。间隙锁基于下面将会提到的`Next-Key Locking` 算法，请务必牢记：**使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据**。

**GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况**

**临键锁(Next-key Locks)**： **临键锁**，是**记录锁与间隙锁的组合**，它的封锁范围，既包含索引记录，又包含索引区间。(临键锁的主要目的，也是为了避免**幻读**(Phantom Read)。**如果把事务的隔离级别降级为RC，临键锁则也会失效**。)

**Next-Key 可以理解为一种特殊的间隙锁，也可以理解为一种特殊的算法**。**【通过临建锁可以解决幻读的问题】**。 每个数据行上的非唯一索引列上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。

需要强调的一点是，**`InnoDB` 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。**

- 对于行的查询，都是采用该方法，主要目的是解决幻读的问题。

> select for update有什么含义，会锁表还是锁行还是其他

**for update 仅适用于InnoDB，且必须在事务块(BEGIN/COMMIT)中才能生效**。在进行事务操作时，通过“for update”语句，MySQL会对查询结果集中每行数据都添加排他锁，其他线程对该记录的更新与删除操作都会阻塞。排他锁包含行锁、表锁。

InnoDB这种行锁实现特点意味着：**只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！**

### 死锁

**死锁产生**：

- 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环
- 当事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁
- 锁的行为和顺序和存储引擎相关。以同样的顺序执行语句，有些存储引擎会产生死锁有些不会——死锁有双重原因：**真正的数据冲突；存储引擎的实现方式**。

**检测死锁**：数据库系统实现了各种死锁检测和死锁超时的机制。InnoDB存储引擎能检测到死锁的循环依赖并立即返回一个错误。

**死锁恢复**：死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。

**外部锁的死锁检测**：发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁， 这需要通过设置锁等待超时参数 innodb_lock_wait_timeout 来解决

**死锁影响性能**：死锁会影响性能而不是会产生严重错误，因为InnoDB会自动检测死锁状况并回滚其中一个受影响的事务。在高并发系统上，当许多线程等待同一个锁时，死锁检测可能导致速度变慢。 有时当发生死锁时，禁用死锁检测（使用innodb_deadlock_detect配置选项）可能会更有效，这时可以依赖`innodb_lock_wait_timeout`设置进行事务回滚。

**MyISAM避免死锁**：

- 在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，所以 MyISAM 表不会出现死锁。

**InnoDB避免死锁**：

- 为了在单个InnoDB表上执行多个并发写入操作时避免死锁，可以在事务开始时通过为预期要修改的每个元祖（行）使用`SELECT ... FOR UPDATE`语句来获取必要的锁，即使这些行的更改语句是在之后才执行的。
- 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁、更新时再申请排他锁，因为这时候当用户再申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁
- 如果事务需要修改或锁定多个表，则应在每个事务中以相同的顺序使用加锁语句。 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会
- 通过`SELECT ... LOCK IN SHARE MODE`获取行的读锁后，如果当前事务再需要对该记录进行更新操作，则很有可能造成死锁。
- 改变事务隔离级别

**如果出现死锁，可以用 `show engine innodb status;`命令来确定最后一个死锁产生的原因**。返回结果中包括死锁相关事务的详细信息，如引发死锁的 SQL 语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。

## 分区

一般情况下我们创建的表对应一组存储文件，使用`MyISAM`存储引擎时是一个`.MYI`和`.MYD`文件，使用`Innodb`存储引擎时是一个`.ibd`和`.frm`（表结构）文件。

**当数据量较大时（一般千万条记录级别以上），MySQL的性能就会开始下降，这时我们就需要将数据分散到多组存储文件，保证其单个文件的执行效率**

**分区类型及操作**

- pange分区
- list分区
- hash分区
- key分区

**RANGE分区**：基于属于一个给定连续区间的列值，把多行分配给分区。mysql将会根据指定的拆分策略，,把数据放在不同的表文件上。相当于在文件上,被拆成了小块.但是,对外给客户的感觉还是一张表，透明的。

按照 range 来分，就是每个库一段连续的数据，这个一般是按比如**时间范围**来的，比如交易表啊，销售表啊等，可以根据年月来存放数据。可能会产生热点问题，大量的流量都打在最新的数据上了。

range 来分，好处在于说，扩容的时候很简单。

**LIST分区**：类似于按RANGE分区，每个分区必须明确定义。它们的主要区别在于，LIST分区中每个分区的定义和选择是基于某列的值从属于一个值列表集中的一个值，而RANGE分区是从属于一个连续区间值的集合。

**HASH分区**：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL 中有效的、产生非负整数值的任何表达式。

hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表

**KEY分区**：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值。

## 分表

**垂直拆分**

垂直分表，通常是按照业务功能的使用频次，把主要的、热门的字段放在一起做为主要表。然后把不常用的，按照各自的业务属性进行聚集，拆分到不同的次要表中；**主要表和次要表的关系一般都是一对一的**。【**一般是用主键作为约束**】

**水平拆分(数据分片)**

单表的容量不超过500W，否则建议水平拆分。是把一个表复制成同样表结构的不同表，然后把数据按照一定的规则划分，分别存储到这些表中，从而保证单表的容量不会太大，提升性能；当然这些结构一样的表，可以放在一个或多个数据库中。

水平分割的几种方法：

- 使用**MD5哈希**，做法是对UID进行md5加密，然后取前几位（我们这里取前两位），然后就可以将不同的UID哈希到不同的用户表（user_xx）中了。
- 还可**根据时间**放入不同的表，比如：article_201601，article_201602。
- 按**热度拆分**，高点击率的词条生成各自的一张表，低热度的词条都放在一张大表里，待低热度的词条达到一定的贴数后，再把低热度的表单独拆分成一张表。
- 根据**ID的值放入对应的表**，第一个表user_0000，第二个100万的用户数据放在第二 个表user_0001中，随用户增加，直接添加用户表就行了。

## 分库

> 为什么要分库?

数据库集群环境后都是多台 slave，基本满足了读取操作;  但是写入或者说大数据、频繁的写入操作对master性能影响就比较大，这个时候，单库并不能解决大规模并发写入的问题，所以就会考虑分库。

> 分库是什么？

一个库里表太多了，导致了海量数据，系统性能下降，把原本存储于一个库的表拆分存储到多个库上， 通常是将表按照功能模块、关系密切程度划分出来，部署到不同库上。

优点：

- 减少增量数据写入时的锁对查询的影响
- **由于单表数量下降，常见的查询操作由于减少了需要扫描的记录，使得单表单次查询所需的检索行数变少，减少了磁盘IO，时延变短**

微服务下，数据库本来就是分库的

## 主从复制

- `master`将改变记录到二进制日志`binary log`。这些记录过程叫做二进制日志事件`binary log events`

- `salve` 将 `master` 的 `binary log events` 拷贝到它的中继日志`relay log`

- `slave` 重做中继日志中的事件，将改变应用到自己的数据库中。**MySQL复制是异步且是串行化的。**

复制的基本原则:

- 每个`slave`只有一个 `master`
- 每个`salve`只能有一个唯一的服务器 ID【mysql_id唯一性】
- 每个`master`可以有多个`salve`

## 三个范式

- 第一范式（1NF）：数据库表中的字段都是单一属性的，不可再分。这个单一属性由基本类型构成，包括整型、实数、字符型、逻辑型、日期型等。
- 第二范式（2NF）：数据库表中不存在非关键字段对任一候选关键字段的部分函数依赖（部分函数依赖指的是存在组合关键字中的某些字段决定非关键字段的情况），也即所有非关键字段都完全依赖于任意一组候选关键字。
- 第三范式（3NF）：在第二范式的基础上，数据表中如果不存在非关键字段对任一候选关键字段的传递函数依赖则符合第三范式。所谓传递函数依赖，指的是如 果存在"A → B → C"的决定关系，则C传递函数依赖于A。因此，满足第三范式的数据库表应该不存在如下依赖关系： 关键字段 → 非关键字段 x → 非关键字段y

## 百万级别或以上的数据如何删除

关于索引：由于**索引需要额外的维护成本**，因为**索引文件是单独存在的文件**,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询MySQL官方手册得知删除数据的速度和创建的索引数量是成正比的。

1. 所以我们想要删除百万数据的时候可以先删除索引（此时大概耗时三分多钟）
2. 然后删除其中无用数据（此过程需要不到两分钟）
3. 删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。
4. 与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了

**先删除索引--->再删除无用数据----> 对留下来的数据重新简历索引,避免索引丢失**

## 参考资料

- <https://juejin.cn/post/6850037271233331208#comment>

- <https://juejin.cn/post/6850037271233331208#heading-52>
